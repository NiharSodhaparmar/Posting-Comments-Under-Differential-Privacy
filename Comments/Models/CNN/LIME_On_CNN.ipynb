{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSPNG3HBbX2G",
        "outputId": "9b6f31a1-78f2-42af-93e9-fb1d5b7bc769"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QueFqUKBJ78y",
        "outputId": "6a08d1c6-528b-4736-f3c4-48533d0055f3"
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjrAGe6JZd_Q"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from operator import itemgetter\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlHUOLCJaJtC"
      },
      "outputs": [],
      "source": [
        "def load_data(data_file):\n",
        "  # read csv file\n",
        "  df = pd.read_csv(data_file)\n",
        "\n",
        "  # replace nan(no value) comment with \"\"(empty string)\n",
        "  df.fillna(\"\", inplace=True)\n",
        "\n",
        "  comments = df['comments'].tolist()\n",
        "  genders = df['labels'].tolist()\n",
        "\n",
        "  genders = [0 if gender == \"Male\" else 1 for gender in genders]\n",
        "\n",
        "  return comments, genders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8z5TPIia0Pu"
      },
      "outputs": [],
      "source": [
        "comments, genders = load_data('/content/drive/MyDrive/Datasets/Bert Modal On One Comment Full Data/cleaned_dataset.csv')\n",
        "\n",
        "# df = pd.DataFrame(list(zip(comments, genders)),\n",
        "#                columns =['comments', 'genders'])\n",
        "\n",
        "# print(df)\n",
        "\n",
        "comments = np.array(comments)\n",
        "genders = np.array(genders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzNfotYmqyxS"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 300\n",
        "MAX_NUM_WORDS = 50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Tazb1KqWVp",
        "outputId": "db3fe6ea-c514-4540-c98f-425a151d3ab7"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(comments)\n",
        "sequences = tokenizer.texts_to_sequences(comments)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slc-u6Tz_G5q",
        "outputId": "365ea12e-3d12-4c9c-b48f-a10725561a6d"
      },
      "outputs": [],
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = to_categorical(genders)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-6FaheGa3-_",
        "outputId": "3372fb76-fc0b-4720-f83b-4ab70f9306dd"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=genders,\n",
        "                                                    random_state=42)\n",
        "print(len(X_train),len( X_test), len(y_train),len( y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l2jxSn1_8_S"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 60\n",
        "num_words = MAX_NUM_WORDS\n",
        "embedding_layer = Embedding(num_words,EMBEDDING_DIM,input_length=MAX_SEQUENCE_LENGTH,trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6QERjTlABhb",
        "outputId": "707824a3-f056-4b8b-b5f0-dc820418dbd3"
      },
      "outputs": [],
      "source": [
        "# Model Building\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(64, 3, activation='relu')(embedded_sequences)\n",
        "x = Conv1D(64, 3, activation='relu')(x)\n",
        "x = MaxPooling1D(2)(x)\n",
        "x=Flatten()(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "preds = Dense(2, activation='softmax')(x)\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfOIZm2iAWJB",
        "outputId": "dfb92b80-ee76-4b51-e136-cfe7b69a00a8"
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "\n",
        "model.fit(X_train, y_train,batch_size=50, epochs=30, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUZe1ioWAWwB",
        "outputId": "4bbd6634-72ab-469e-d1ef-c928c17e2e43"
      },
      "outputs": [],
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrxGR-_ZC0nD"
      },
      "outputs": [],
      "source": [
        "def predict_proba(arr):\n",
        "  sequences_new = tokenizer.texts_to_sequences(arr)\n",
        "  data = pad_sequences(sequences_new, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  yprob = model.predict(data, verbose=None)\n",
        "  # yclasses=yprob.argmax(axis=-1)\n",
        "\n",
        "  returnable=[]\n",
        "  for i in yprob:\n",
        "    temp=i[0]\n",
        "    returnable.append(np.array([temp,1-temp])) #I would recommend rounding temp and 1-temp off to 2 places\n",
        "  return np.array(returnable)\n",
        "\n",
        "  # return yclasses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5x5BEbKGQwj"
      },
      "outputs": [],
      "source": [
        "def predict_male_or_female(txt):\n",
        "    arr = np.array([txt])\n",
        "    sequences_new = tokenizer.texts_to_sequences(arr)\n",
        "    data = pad_sequences(sequences_new, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    yprob = model.predict(data, verbose=None)\n",
        "    yclasses=yprob.argmax(axis=-1)\n",
        "\n",
        "    return yclasses[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw8_ysvQfiza"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# predictions = predict_proba(comments)\n",
        "\n",
        "# accuracy = accuracy_score(genders, predictions)\n",
        "# print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# report = classification_report(genders, predictions)\n",
        "# print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nakuPQ0GaWX",
        "outputId": "218c73dd-7cea-4753-c843-6f7bad201932"
      },
      "outputs": [],
      "source": [
        "txt = \"I've had the 50watter since Oct of last year and I'm still impressed and blown away every time I play it. It's unreal. Killer choice\"\n",
        "\n",
        "print(predict_male_or_female(txt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAalYDuTGdG-"
      },
      "outputs": [],
      "source": [
        "class_names=['Male','Female']\n",
        "explainer= LimeTextExplainer(class_names=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stox1UrpKAIS"
      },
      "outputs": [],
      "source": [
        "# txt = \"I've had the 50watter since Oct of last year and I'm still impressed and blown away every time I play it. It's unreal. Killer choice\"\n",
        "# txt = \"This is a great picture of u!!!! Beautiful\"\n",
        "\n",
        "# explainer.explain_instance(txt,predict_proba).show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0lHwMAcKDU8"
      },
      "outputs": [],
      "source": [
        "def sort_tuples_array_by_second_item(tuples):\n",
        "    # Sort the tuples by the second item using the itemgetter function\n",
        "    return sorted(tuples, key=itemgetter(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-HQV-dQqPfn"
      },
      "outputs": [],
      "source": [
        "def get_max_explained_words(txt):\n",
        "\n",
        "  prediction = predict_male_or_female(txt)\n",
        "  # print(\" \")\n",
        "  # print(\"prediction\")\n",
        "  # print(prediction)\n",
        "\n",
        "  exp = explainer.explain_instance(txt, predict_proba)\n",
        "\n",
        "  exp_list = []\n",
        "  for x in zip(exp.local_exp[1], exp.as_list()):\n",
        "    exp_list.append((x[1][0], x[1][1], x[0][0]))\n",
        "\n",
        "  # print(\"exp_list\")\n",
        "  # print(exp_list)\n",
        "\n",
        "  # features with negative score are for Male class\n",
        "  male_list = list(filter(lambda x: x[1] < 0, exp_list))\n",
        "  male_list = sort_tuples_array_by_second_item(male_list)\n",
        "\n",
        "  # print(\"male_list\")\n",
        "  # print(male_list)\n",
        "  # print(len(male_list))\n",
        "\n",
        "  # features with positive score are for female class\n",
        "  female_list = list(filter(lambda x: x[1] > 0, exp_list))\n",
        "  female_list = sort_tuples_array_by_second_item(female_list)\n",
        "\n",
        "  # print(\"female_list\")\n",
        "  # print(female_list)\n",
        "  # print(len(female_list))\n",
        "\n",
        "  # # min is used while the male score is negative\n",
        "  male_mc = min(male_list, key=itemgetter(1)) if len(male_list) else None\n",
        "\n",
        "  # print(\"male_mc\")\n",
        "  # print(male_mc)\n",
        "\n",
        "  # max is used while the female score is negative\n",
        "  female_mc = max(female_list, key=itemgetter(1)) if len(female_list) else None\n",
        "\n",
        "  # print(\"female_mc\")\n",
        "  # print(female_mc)\n",
        "\n",
        "  # if comment predicted Male\n",
        "  if prediction == 0:\n",
        "    if len(male_list) > 1:\n",
        "      male_mc = male_list[0]\n",
        "      if (male_mc, 0) in words:\n",
        "        words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "      else:\n",
        "        words[(male_mc[0], 0)] = {}\n",
        "        words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "        wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "\n",
        "      male_mc = male_list[1]\n",
        "      if (male_mc, 0) in words:\n",
        "        words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "      else:\n",
        "        words[(male_mc[0], 0)] = {}\n",
        "        words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "        wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "    elif len(male_list) == 1:\n",
        "      male_mc = male_list[0]\n",
        "      if (male_mc, 0) in words:\n",
        "        words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "      else:\n",
        "        words[(male_mc[0], 0)] = {}\n",
        "        words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "        wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "\n",
        "  else:\n",
        "    if len(female_list) > 1:\n",
        "      female_mc = female_list[(len(female_list)-1)]\n",
        "      if (female_mc, 1) in words:\n",
        "        words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "      else:\n",
        "        words[(female_mc[0], 1)] = {}\n",
        "        words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "        wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "      female_mc = female_list[(len(female_list)-2)]\n",
        "      if (female_mc, 1) in words:\n",
        "        words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "      else:\n",
        "        words[(female_mc[0], 1)] = {}\n",
        "        words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "        wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "    elif len(female_list) == 1:\n",
        "      female_mc = female_list[0]\n",
        "      if (female_mc, 1) in words:\n",
        "        words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "      else:\n",
        "        words[(female_mc[0], 1)] = {}\n",
        "        words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "        wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "  # -------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Male words\n",
        "  # if male_mc is not None:\n",
        "  #   if (male_mc, 0) in words:\n",
        "  #     words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "  #     words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "  #   else:\n",
        "  #     words[(male_mc[0], 0)] = {}\n",
        "  #     words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "  #     words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "  #     wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "\n",
        "  #Female Words\n",
        "  # if female_mc is not None:\n",
        "  #   if (female_mc, 1) in words:\n",
        "  #     words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "  #     words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "  #   else:\n",
        "  #     words[(female_mc[0], 1)] = {}\n",
        "  #     words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "  #     words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "  #     wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "  return words, wordsForCSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPzs3Q_7qSHW"
      },
      "outputs": [],
      "source": [
        "def load_original_data(data_file):\n",
        "  # read csv file\n",
        "  df = pd.read_csv(data_file)\n",
        "\n",
        "  # replace nan(no value) comment with \"\"(empty string)\n",
        "  df.fillna(\"\", inplace=True)\n",
        "\n",
        "  comments = df['comment'].tolist()\n",
        "  genders = df['user_gender'].tolist()\n",
        "\n",
        "  genders = [0 if gender == \"Male\" else 1 for gender in genders]\n",
        "\n",
        "  return comments, genders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q60RrYPjqfuT"
      },
      "outputs": [],
      "source": [
        "original_comments, original_genders = load_original_data('/content/drive/MyDrive/Datasets/dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNQml0_NqhPA"
      },
      "outputs": [],
      "source": [
        "n = int(len(original_comments) / 14)\n",
        "x = [original_comments[i:i + n] for i in range(0, len(original_comments), n)]\n",
        "y = [original_genders[i:i + n] for i in range(0, len(original_genders), n)]\n",
        "\n",
        "first_half_comments = x[0]\n",
        "second_half_comments = x[1]\n",
        "third_half_comments = x[2]\n",
        "fourth_half_comments = x[3]\n",
        "fifth_half_comments = x[4]\n",
        "sixth_half_comments = x[5]\n",
        "seventh_half_comments = x[6]\n",
        "eighth_half_comments = x[7]\n",
        "ninth_half_comments = x[8]\n",
        "tenth_half_comments = x[9]\n",
        "eleventh_half_comments = x[10]\n",
        "twelveth_half_comments = x[11]\n",
        "thirteenth_half_comments = x[12]\n",
        "fourteenth_half_comments = x[13]\n",
        "\n",
        "first_half_genders = y[0]\n",
        "second_half_genders = y[1]\n",
        "third_half_genders = y[2]\n",
        "fourth_half_genders = y[3]\n",
        "fifth_half_genders = x[4]\n",
        "sixth_half_genders = x[5]\n",
        "seventh_half_genders = x[6]\n",
        "eighth_half_genders = x[7]\n",
        "ninth_half_genders = x[8]\n",
        "tenth_half_genders = x[9]\n",
        "eleventh_half_genders = x[10]\n",
        "twelveth_half_genders = x[11]\n",
        "thirteenth_half_genders = x[12]\n",
        "fourteenth_half_genders = x[13]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RbsfTbdqje_",
        "outputId": "36bbb3ce-af92-48bb-eca8-18b7f28ae00a"
      },
      "outputs": [],
      "source": [
        "print(len(first_half_comments))\n",
        "print(len(second_half_comments))\n",
        "print(len(third_half_comments))\n",
        "print(len(fourth_half_comments))\n",
        "print(len(fifth_half_comments))\n",
        "print(len(sixth_half_comments))\n",
        "print(len(seventh_half_comments))\n",
        "print(len(eighth_half_comments))\n",
        "print(len(ninth_half_comments))\n",
        "print(len(tenth_half_comments))\n",
        "print(len(eleventh_half_comments))\n",
        "print(len(twelveth_half_comments))\n",
        "print(len(thirteenth_half_comments))\n",
        "print(len(fourteenth_half_comments))\n",
        "\n",
        "\n",
        "print(\"=====================\")\n",
        "print(len(first_half_genders))\n",
        "print(len(second_half_genders))\n",
        "print(len(third_half_genders))\n",
        "print(len(fourth_half_genders))\n",
        "print(len(fifth_half_genders))\n",
        "print(len(sixth_half_genders))\n",
        "print(len(seventh_half_genders))\n",
        "print(len(eighth_half_genders))\n",
        "print(len(ninth_half_genders))\n",
        "print(len(tenth_half_genders))\n",
        "print(len(eleventh_half_genders))\n",
        "print(len(twelveth_half_genders))\n",
        "print(len(thirteenth_half_genders))\n",
        "print(len(fourteenth_half_genders))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBGRJ1KvqpBF",
        "outputId": "27393d02-3bca-45b4-dd82-2129131a343b"
      },
      "outputs": [],
      "source": [
        "words = {}\n",
        "wordsForCSV = []\n",
        "\n",
        "for comment in tqdm(first_half_comments, total = len(first_half_comments)):\n",
        "    words, wordsForCSV = get_max_explained_words(comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWKoe-tSqr58"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "header=[\"word\", \"label\", \"limescore\"]\n",
        "\n",
        "with open('/content/drive/MyDrive/Datasets/CNN/1_extracted_strong_words_by_rnn.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # write multiple rows\n",
        "    writer.writerows(wordsForCSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBp_ReI3rL2y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
