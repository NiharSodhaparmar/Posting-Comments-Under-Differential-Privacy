{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HMFkPr-3KJK",
        "outputId": "e1194410-726d-4a36-a42d-b7e950f3d882"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soPtsD5V3hlI",
        "outputId": "702ce2b1-82b5-4080-d398-f16f9385fad3"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8UQRKWw3x6_",
        "outputId": "9567f7bf-08f6-4cc6-95b8-3f876dc399ec"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import string\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Convolution1D\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tqdm import tqdm\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjDh_OfF31Og"
      },
      "outputs": [],
      "source": [
        "def load_data(data_file):\n",
        "  # read csv file\n",
        "  df = pd.read_csv(data_file)\n",
        "\n",
        "  # replace nan(no value) comment with \"\"(empty string)\n",
        "  df.fillna(\"\", inplace=True)\n",
        "\n",
        "  comments = df['comments'].tolist()\n",
        "  genders = df['labels'].tolist()\n",
        "\n",
        "  genders = [0 if gender == \"Male\" else 1 for gender in genders]\n",
        "\n",
        "  return comments, genders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhBmLhjt34N4"
      },
      "outputs": [],
      "source": [
        "comments, genders = load_data('/content/drive/MyDrive/Datasets/Bert Modal On One Comment Full Data/cleaned_dataset.csv')\n",
        "\n",
        "# df = pd.DataFrame(list(zip(comments, genders)),\n",
        "#                columns =['comments', 'genders'])\n",
        "\n",
        "# print(df)\n",
        "\n",
        "comments = np.array(comments)\n",
        "genders = np.array(genders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNP-g46p37iY",
        "outputId": "174347a4-8cdf-4ea2-fab6-d66a39a78685"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(comments, genders,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=genders,\n",
        "                                                    random_state=42)\n",
        "print(len(X_train),len( X_test), len(y_train),len( y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXazaIlk3_rq"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "top_words = 10000\n",
        "max_comment_length = 300\n",
        "embedding_vecor_length = 64\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5kbuK6nNMCm"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(list_tokenized_train, maxlen=max_comment_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILd4ElMS4Fqn",
        "outputId": "9a8f6a30-f2fb-4668-f44b-c2a193738746"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_comment_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHYVBMnF4tnB",
        "outputId": "22cb96d0-4024-45f0-c63f-0ce32913c229"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train,y_train, epochs=2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQNCkOmU4Hn4",
        "outputId": "8d514a3e-0406-44f0-e900-3f9fa7d327e3"
      },
      "outputs": [],
      "source": [
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=max_comment_length)\n",
        "prediction = model.predict(X_test)\n",
        "y_pred = (prediction > 0.5)\n",
        "print(\"Accuracy of the model : \", accuracy_score(y_pred, y_test))\n",
        "print('F1-score: ', f1_score(y_pred, y_test))\n",
        "print('Confusion matrix:')\n",
        "confusion_matrix(y_test,y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clI1eDqJPpYM"
      },
      "outputs": [],
      "source": [
        "def predict_proba(arr):\n",
        "  list_tokenized_ex = tokenizer.texts_to_sequences(arr)\n",
        "  Ex = pad_sequences(list_tokenized_ex, maxlen=max_comment_length)\n",
        "  pred=model.predict(Ex, verbose=None)\n",
        "  returnable=[]\n",
        "  for i in pred:\n",
        "    temp=i[0]\n",
        "    returnable.append(np.array([1-temp,temp])) #I would recommend rounding temp and 1-temp off to 2 places\n",
        "  return np.array(returnable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoSerTxP9UrO"
      },
      "outputs": [],
      "source": [
        "def predict_male_or_female(txt):\n",
        "    arr = np.array([txt])\n",
        "    list_tokenized_test = tokenizer.texts_to_sequences(arr)\n",
        "    test_instance = pad_sequences(list_tokenized_test, maxlen=max_comment_length)\n",
        "    prediction = model.predict(test_instance, verbose=None)\n",
        "    y_pred = prediction[0][0]\n",
        "    pred = 0\n",
        "    if(y_pred > 0.5):\n",
        "        pred = 1\n",
        "    else:\n",
        "        pred = 0\n",
        "    # y_pred = (prediction > 0.5)\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmWQW9K88ZOa",
        "outputId": "50a84136-733c-4b01-846b-eef5e7dd6bb3"
      },
      "outputs": [],
      "source": [
        "txt = \"I've had the 50watter since Oct of last year and I'm still impressed and blown away every time I play it. It's unreal. Killer choice\"\n",
        "\n",
        "print(predict_male_or_female(txt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhtFPbZWQRTh"
      },
      "outputs": [],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "class_names=['Male','Female']\n",
        "explainer= LimeTextExplainer(class_names=class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "H78Q02Q8QStN",
        "outputId": "1f4e5e69-4cd7-448c-a67f-04b753626224"
      },
      "outputs": [],
      "source": [
        "explainer.explain_instance(\"I've had the 50watter since Oct of last year and I'm still impressed and blown away every time I play it. It's unreal. Killer choice\",predict_proba).show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_JWuF8aTAKx"
      },
      "outputs": [],
      "source": [
        "def sort_tuples_array_by_second_item(tuples):\n",
        "    # Sort the tuples by the second item using the itemgetter function\n",
        "    return sorted(tuples, key=itemgetter(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LPuLu4sKtyd"
      },
      "outputs": [],
      "source": [
        "def get_max_explained_words(txt):\n",
        "\n",
        "  prediction = predict_male_or_female(txt)\n",
        "  # print(\" \")\n",
        "  # print(\"prediction\")\n",
        "  # print(prediction)\n",
        "\n",
        "  exp = explainer.explain_instance(txt, predict_proba)\n",
        "\n",
        "  exp_list = []\n",
        "  for x in zip(exp.local_exp[1], exp.as_list()):\n",
        "    exp_list.append((x[1][0], x[1][1], x[0][0]))\n",
        "\n",
        "  # print(\"exp_list\")\n",
        "  # print(exp_list)\n",
        "\n",
        "  # features with negative score are for Male class\n",
        "  male_list = list(filter(lambda x: x[1] < 0, exp_list))\n",
        "  male_list = sort_tuples_array_by_second_item(male_list)\n",
        "\n",
        "  # print(\"male_list\")\n",
        "  # print(male_list)\n",
        "  # print(len(male_list))\n",
        "\n",
        "  # features with positive score are for female class\n",
        "  female_list = list(filter(lambda x: x[1] > 0, exp_list))\n",
        "  female_list = sort_tuples_array_by_second_item(female_list)\n",
        "\n",
        "  # print(\"female_list\")\n",
        "  # print(female_list)\n",
        "  # print(len(female_list))\n",
        "\n",
        "  # # min is used while the male score is negative\n",
        "  male_mc = min(male_list, key=itemgetter(1)) if len(male_list) else None\n",
        "\n",
        "  # print(\"male_mc\")\n",
        "  # print(male_mc)\n",
        "\n",
        "  # max is used while the female score is negative\n",
        "  female_mc = max(female_list, key=itemgetter(1)) if len(female_list) else None\n",
        "\n",
        "  # print(\"female_mc\")\n",
        "  # print(female_mc)\n",
        "\n",
        "  # if comment predicted Male\n",
        "  if prediction == 0:\n",
        "    if len(male_list) > 1:\n",
        "      male_mc = male_list[0]\n",
        "      if (male_mc, 0) in words:\n",
        "        words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "      else:\n",
        "        words[(male_mc[0], 0)] = {}\n",
        "        words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "        wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "\n",
        "      male_mc = male_list[1]\n",
        "      if (male_mc, 0) in words:\n",
        "        words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "      else:\n",
        "        words[(male_mc[0], 0)] = {}\n",
        "        words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "        wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "    elif len(male_list) == 1:\n",
        "      male_mc = male_list[0]\n",
        "      if (male_mc, 0) in words:\n",
        "        words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "      else:\n",
        "        words[(male_mc[0], 0)] = {}\n",
        "        words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "        words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "        wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "\n",
        "  else:\n",
        "    if len(female_list) > 1:\n",
        "      female_mc = female_list[(len(female_list)-1)]\n",
        "      if (female_mc, 1) in words:\n",
        "        words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "      else:\n",
        "        words[(female_mc[0], 1)] = {}\n",
        "        words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "        wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "      female_mc = female_list[(len(female_list)-2)]\n",
        "      if (female_mc, 1) in words:\n",
        "        words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "      else:\n",
        "        words[(female_mc[0], 1)] = {}\n",
        "        words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "        wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "    elif len(female_list) == 1:\n",
        "      female_mc = female_list[0]\n",
        "      if (female_mc, 1) in words:\n",
        "        words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "      else:\n",
        "        words[(female_mc[0], 1)] = {}\n",
        "        words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "        words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "        wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "  # -------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Male words\n",
        "  # if male_mc is not None:\n",
        "  #   if (male_mc, 0) in words:\n",
        "  #     words[(male_mc[0], 0)]['lime_score'].extend(male_mc[1])\n",
        "  #     words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "  #   else:\n",
        "  #     words[(male_mc[0], 0)] = {}\n",
        "  #     words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "  #     words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "  #     wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "\n",
        "  #Female Words\n",
        "  # if female_mc is not None:\n",
        "  #   if (female_mc, 1) in words:\n",
        "  #     words[(female_mc[0], 1)]['lime_score'].extend(female_mc[1])\n",
        "  #     words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "  #   else:\n",
        "  #     words[(female_mc[0], 1)] = {}\n",
        "  #     words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "  #     words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "  #     wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "  return words, wordsForCSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeo_Cm6tDOWw"
      },
      "outputs": [],
      "source": [
        "# txt = \"This is a great picture of u!!!! Beautiful\"\n",
        "\n",
        "# words, wordsForCSV = get_max_explained_words(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlUgtyUtQdI_"
      },
      "outputs": [],
      "source": [
        "def load_original_data(data_file):\n",
        "  # read csv file\n",
        "  df = pd.read_csv(data_file)\n",
        "\n",
        "  # replace nan(no value) comment with \"\"(empty string)\n",
        "  df.fillna(\"\", inplace=True)\n",
        "\n",
        "  comments = df['comment'].tolist()\n",
        "  genders = df['user_gender'].tolist()\n",
        "\n",
        "  genders = [0 if gender == \"Male\" else 1 for gender in genders]\n",
        "\n",
        "  return comments, genders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUFkYnb4Qd5V"
      },
      "outputs": [],
      "source": [
        "original_comments, original_genders = load_original_data('/content/drive/MyDrive/Datasets/dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBxerrkGQ-De"
      },
      "outputs": [],
      "source": [
        "n = int(len(original_comments) / 14)\n",
        "x = [original_comments[i:i + n] for i in range(0, len(original_comments), n)]\n",
        "y = [original_genders[i:i + n] for i in range(0, len(original_genders), n)]\n",
        "\n",
        "first_half_comments = x[0]\n",
        "second_half_comments = x[1]\n",
        "third_half_comments = x[2]\n",
        "fourth_half_comments = x[3]\n",
        "fifth_half_comments = x[4]\n",
        "sixth_half_comments = x[5]\n",
        "seventh_half_comments = x[6]\n",
        "eighth_half_comments = x[7]\n",
        "ninth_half_comments = x[8]\n",
        "tenth_half_comments = x[9]\n",
        "eleventh_half_comments = x[10]\n",
        "twelveth_half_comments = x[11]\n",
        "thirteenth_half_comments = x[12]\n",
        "fourteenth_half_comments = x[13]\n",
        "\n",
        "first_half_genders = y[0]\n",
        "second_half_genders = y[1]\n",
        "third_half_genders = y[2]\n",
        "fourth_half_genders = y[3]\n",
        "fifth_half_genders = x[4]\n",
        "sixth_half_genders = x[5]\n",
        "seventh_half_genders = x[6]\n",
        "eighth_half_genders = x[7]\n",
        "ninth_half_genders = x[8]\n",
        "tenth_half_genders = x[9]\n",
        "eleventh_half_genders = x[10]\n",
        "twelveth_half_genders = x[11]\n",
        "thirteenth_half_genders = x[12]\n",
        "fourteenth_half_genders = x[13]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzVoWJQXREem",
        "outputId": "3a18acf9-c675-43af-86ba-fae2d0e33539"
      },
      "outputs": [],
      "source": [
        "print(len(first_half_comments))\n",
        "print(len(second_half_comments))\n",
        "print(len(third_half_comments))\n",
        "print(len(fourth_half_comments))\n",
        "print(len(fifth_half_comments))\n",
        "print(len(sixth_half_comments))\n",
        "print(len(seventh_half_comments))\n",
        "print(len(eighth_half_comments))\n",
        "print(len(ninth_half_comments))\n",
        "print(len(tenth_half_comments))\n",
        "print(len(eleventh_half_comments))\n",
        "print(len(twelveth_half_comments))\n",
        "print(len(thirteenth_half_comments))\n",
        "print(len(fourteenth_half_comments))\n",
        "\n",
        "\n",
        "print(\"=====================\")\n",
        "print(len(first_half_genders))\n",
        "print(len(second_half_genders))\n",
        "print(len(third_half_genders))\n",
        "print(len(fourth_half_genders))\n",
        "print(len(fifth_half_genders))\n",
        "print(len(sixth_half_genders))\n",
        "print(len(seventh_half_genders))\n",
        "print(len(eighth_half_genders))\n",
        "print(len(ninth_half_genders))\n",
        "print(len(tenth_half_genders))\n",
        "print(len(eleventh_half_genders))\n",
        "print(len(twelveth_half_genders))\n",
        "print(len(thirteenth_half_genders))\n",
        "print(len(fourteenth_half_genders))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdFub-i9DRX_",
        "outputId": "4f02f405-2b62-4647-ce8e-2dc772b90c06"
      },
      "outputs": [],
      "source": [
        "words = {}\n",
        "wordsForCSV = []\n",
        "\n",
        "for comment in tqdm(first_half_comments, total = len(first_half_comments)):\n",
        "    words, wordsForCSV = get_max_explained_words(comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-qyYqqcGr9v"
      },
      "outputs": [],
      "source": [
        "# print(wordsForCSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_wraoDFGzrn"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "header=[\"word\", \"label\", \"limescore\"]\n",
        "\n",
        "with open('/content/drive/MyDrive/Datasets/RNN/1_extracted_strong_words_by_rnn.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # write multiple rows\n",
        "    writer.writerows(wordsForCSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-7VNc5VOS7b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
