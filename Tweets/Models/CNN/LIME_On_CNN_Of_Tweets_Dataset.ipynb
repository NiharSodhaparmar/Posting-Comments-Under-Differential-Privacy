{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHYKUrZnls_P",
    "outputId": "9a598711-acb4-4e21-dd1e-fa8d9d8ca902"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcitcR1Yh_Zn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pVTwFfdiTnu"
   },
   "outputs": [],
   "source": [
    "def load_data(data_file):\n",
    "  # read csv file\n",
    "  df = pd.read_csv(data_file)\n",
    "\n",
    "  # replace nan(no value) comment with \"\"(empty string)\n",
    "  df.fillna(\"\", inplace=True)\n",
    "\n",
    "  tweets = df['Tweet'].tolist()\n",
    "  labels = df['Party'].tolist()\n",
    "\n",
    "  labels = [0 if label == \"Democrat\" else 1 for label in labels]\n",
    "\n",
    "  return tweets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoVuMD6FiYkT"
   },
   "outputs": [],
   "source": [
    "tweets, labels = load_data('/content/drive/MyDrive/Datasets/Tweets/ExtractedTweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOoNc9weiahs",
    "outputId": "9d32dfd7-1c2c-469f-859e-9e30a6322e69"
   },
   "outputs": [],
   "source": [
    "tweets = np.array(tweets)\n",
    "labels = np.array(labels)\n",
    "\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbmiLwADib_o"
   },
   "outputs": [],
   "source": [
    "new_tweets = tweets[35370:86460]\n",
    "new_labels = labels[35370:86460]\n",
    "\n",
    "n = int(len(new_tweets) / 65)\n",
    "x = [tweets[i:i + n] for i in range(0, len(new_tweets), n)]\n",
    "y = [labels[i:i + n] for i in range(0, len(new_labels), n)]\n",
    "\n",
    "first_half_tweets = x[0]\n",
    "second_half_tweets = x[1]\n",
    "third_half_tweets = x[2]\n",
    "fourth_half_tweets = x[3]\n",
    "fifth_half_tweets = x[4]\n",
    "sixth_half_tweets = x[5]\n",
    "seventh_half_tweets = x[6]\n",
    "eighth_half_tweets = x[7]\n",
    "ninth_half_tweets = x[8]\n",
    "tenth_half_tweets = x[9]\n",
    "eleventh_half_tweets = x[10]\n",
    "twelveth_half_tweets = x[11]\n",
    "thirteenth_half_tweets = x[12]\n",
    "fourteenth_half_tweets = x[13]\n",
    "fifteen_half_tweets = x[14]\n",
    "sixteen_half_tweets = x[15]\n",
    "seventeen_half_tweets = x[16]\n",
    "eighteen_half_tweets = x[17]\n",
    "nineteen_half_tweets = x[18]\n",
    "twenty_half_tweets = x[19]\n",
    "twentyone_half_tweets = x[20]\n",
    "twentytwo_half_tweets = x[21]\n",
    "twentythree_half_tweets = x[22]\n",
    "twentyfour_half_tweets = x[23]\n",
    "twentyfive_half_tweets = x[24]\n",
    "twentysix_half_tweets = x[25]\n",
    "twentyseven_half_tweets = x[26]\n",
    "twentyeight_half_tweets = x[27]\n",
    "twentynine_half_tweets = x[28]\n",
    "thirty_half_tweets = x[29]\n",
    "thirtyone_half_tweets = x[30]\n",
    "thirtytwo_half_tweets = x[31]\n",
    "thirtythree_half_tweets = x[32]\n",
    "thirtyfour_half_tweets = x[33]\n",
    "thirtyfive_half_tweets = x[34]\n",
    "thirtysix_half_tweets = x[35]\n",
    "thirtyseven_half_tweets = x[36]\n",
    "thirtyeight_half_tweets = x[37]\n",
    "thirtynine_half_tweets = x[38]\n",
    "# fourty_half_tweets = x[39]\n",
    "# fourtyone_half_tweets = x[40]\n",
    "# fourtytwo_half_tweets = x[41]\n",
    "# fourtythree_half_tweets = x[42]\n",
    "# fourtyfour_half_tweets = x[43]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "first_half_labels = y[0]\n",
    "second_half_labels = y[1]\n",
    "third_half_labels = y[2]\n",
    "fourth_half_labels = y[3]\n",
    "fifth_half_labels = x[4]\n",
    "sixth_half_labels = x[5]\n",
    "seventh_half_labels = x[6]\n",
    "eighth_half_labels = x[7]\n",
    "ninth_half_labels = x[8]\n",
    "tenth_half_labels = x[9]\n",
    "eleventh_half_labels = x[10]\n",
    "twelveth_half_labels = x[11]\n",
    "thirteenth_half_labels = x[12]\n",
    "fourteenth_half_labels = x[13]\n",
    "fifteen_half_labels = x[14]\n",
    "sixteen_half_labels = x[15]\n",
    "seventeen_half_labels = x[16]\n",
    "eighteen_half_labels = x[17]\n",
    "nineteen_half_labels = x[18]\n",
    "twenty_half_labels = x[19]\n",
    "twentyone_half_labels = x[20]\n",
    "twentytwo_half_labels = x[21]\n",
    "twentythree_half_labels = x[22]\n",
    "twentyfour_half_labels = x[23]\n",
    "twentyfive_half_labels = x[24]\n",
    "twentysix_half_labels = x[25]\n",
    "twentyseven_half_labels = x[26]\n",
    "twentyeight_half_labels = x[27]\n",
    "twentynine_half_labels = x[28]\n",
    "thirty_half_labels = x[29]\n",
    "thirtyone_half_labels = x[30]\n",
    "thirtytwo_half_labels = x[31]\n",
    "thirtythree_half_labels = x[32]\n",
    "thirtyfour_half_labels = x[33]\n",
    "thirtyfive_half_labels = x[34]\n",
    "thirtysix_half_labels = x[35]\n",
    "thirtyseven_half_labels = x[36]\n",
    "thirtyeight_half_labels = x[37]\n",
    "thirtynine_half_labels = x[38]\n",
    "# fourty_half_labels = x[39]\n",
    "# fourtyone_half_labels = x[40]\n",
    "# fourtytwo_half_labels = x[41]\n",
    "# fourtythree_half_labels = x[42]\n",
    "# fourtyfour_half_labels = x[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKF5k4KPieX3"
   },
   "outputs": [],
   "source": [
    "# Tokenize and pad sequences\n",
    "max_words = 50000\n",
    "max_len = 128\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "sequences = tokenizer.texts_to_sequences(tweets)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT7uXCLWk6wr"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8sGIX8vlIAN"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available and set memory growth to avoid issues\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEDU2CN9lNf9"
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "embedding_dim = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Emv32iUlRwV",
    "outputId": "96936ab0-8c30-43ce-a6a0-489ae1f87490"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x42aKRyklTuc",
    "outputId": "d2d89d53-e812-4350-ed5c-48d0d718217c"
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVHwNKaClWBw",
    "outputId": "82909c14-7736-4b05-ef1c-b6e2d6c940bc"
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLt5gERLlcQ9",
    "outputId": "0761de94-3bc0-492c-d4c3-fcb6ae6a675f"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('/content/drive/MyDrive/Datasets/Tweets/Saved Model/tweet_classification_model_cnn.h5')\n",
    "print(\"Model saved to tweet_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOWQaP1Kn6gi"
   },
   "outputs": [],
   "source": [
    "# Define prediction function\n",
    "def predict_party(tweet, tokenizer, model, max_len):\n",
    "    sequence = tokenizer.texts_to_sequences([tweet])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequence)[0][0]\n",
    "    return 'Democrat' if prediction < 0.5 else 'Republican'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9ITeIK8o8PC",
    "outputId": "844a5931-8fba-46e4-d96d-2d2196f925bf"
   },
   "outputs": [],
   "source": [
    "# print(predict_party(tweets[0], tokenizer, model, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTWuA4mspANY"
   },
   "outputs": [],
   "source": [
    "# Define a function to predict probabilities\n",
    "def predict_proba(texts):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "    return np.array([[1 - pred[0], pred[0]] for pred in model.predict(padded_sequences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuV5rvZ-qDVS"
   },
   "outputs": [],
   "source": [
    "# Create a LIME explainer\n",
    "explainer = LimeTextExplainer(class_names=['Democrat', 'Republican'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB42KsuzqE_M"
   },
   "outputs": [],
   "source": [
    "# Function to explain predictions\n",
    "def explain_prediction(tweet):\n",
    "    explanation = explainer.explain_instance(tweet, predict_proba, num_features=10)\n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXTMw5I9qs2z"
   },
   "outputs": [],
   "source": [
    "# Display the explanation\n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1o2nYPo_qzoF"
   },
   "outputs": [],
   "source": [
    "def sort_tuples_array_by_second_item(tuples):\n",
    "    # Sort the tuples by the second item using the itemgetter function\n",
    "    return sorted(tuples, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kO0gMFlfrvHH"
   },
   "outputs": [],
   "source": [
    "def get_max_explained_words(txt):\n",
    "\n",
    "  prediction = predict_party(model, txt, tokenizer, max_len)\n",
    "  # print(\" \")\n",
    "  # print(\"prediction\")\n",
    "  # print(prediction)\n",
    "\n",
    "  exp = explain_prediction(txt)\n",
    "\n",
    "  exp_list = []\n",
    "  for x in zip(exp.local_exp[1], exp.as_list()):\n",
    "    exp_list.append((x[1][0], x[1][1], x[0][0]))\n",
    "\n",
    "  # print(\"exp_list\")\n",
    "  # print(exp_list)\n",
    "\n",
    "  # features with negative score are for Male class\n",
    "  democrat_list = list(filter(lambda x: x[1] < 0, exp_list))\n",
    "  democrat_list = sort_tuples_array_by_second_item(democrat_list)\n",
    "\n",
    "  # print(\"democrat_list\")\n",
    "  # print(democrat_list)\n",
    "  # print(len(democrat_list))\n",
    "\n",
    "  # features with positive score are for female class\n",
    "  republican_list = list(filter(lambda x: x[1] > 0, exp_list))\n",
    "  republican_list = sort_tuples_array_by_second_item(republican_list)\n",
    "\n",
    "  # print(\"republican_list\")\n",
    "  # print(republican_list)\n",
    "  # print(len(republican_list))\n",
    "\n",
    "  # min is used while the democrat score is negative\n",
    "  democrat_mc = min(democrat_list, key=itemgetter(1)) if len(democrat_list) else None\n",
    "\n",
    "  # print(\"democrat_mc\")\n",
    "  # print(democrat_mc)\n",
    "\n",
    "  # max is used while the republican score is negative\n",
    "  republican_mc = max(republican_list, key=itemgetter(1)) if len(republican_list) else None\n",
    "\n",
    "  # print(\"republican_mc\")\n",
    "  # print(republican_mc)\n",
    "\n",
    "  # if comment predicted Male\n",
    "  if prediction == \"Democrat\":\n",
    "    if len(democrat_list) > 1:\n",
    "      democrat_mc = democrat_list[0]\n",
    "      if (democrat_mc, 0) in words:\n",
    "        words[(democrat_mc[0], 0)]['lime_score'].extend(democrat_mc[1])\n",
    "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
    "      else:\n",
    "        words[(democrat_mc[0], 0)] = {}\n",
    "        words[(democrat_mc[0], 0)]['lime_score'] = [democrat_mc[1]]\n",
    "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
    "        wordsForCSV.append([democrat_mc[0], 0, democrat_mc[1]])\n",
    "\n",
    "      democrat_mc = democrat_list[1]\n",
    "      if (democrat_mc, 0) in words:\n",
    "        words[(democrat_mc[0], 0)]['lime_score'].extend(democrat_mc[1])\n",
    "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
    "      else:\n",
    "        words[(democrat_mc[0], 0)] = {}\n",
    "        words[(democrat_mc[0], 0)]['lime_score'] = [democrat_mc[1]]\n",
    "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
    "        wordsForCSV.append([democrat_mc[0], 0, democrat_mc[1]])\n",
    "    elif len(democrat_list) == 1:\n",
    "      democrat_mc = democrat_list[0]\n",
    "      if (democrat_mc, 0) in words:\n",
    "        words[(democrat_mc[0], 0)]['lime_score'].extend(democrat_mc[1])\n",
    "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
    "      else:\n",
    "        words[(democrat_mc[0], 0)] = {}\n",
    "        words[(democrat_mc[0], 0)]['lime_score'] = [democrat_mc[1]]\n",
    "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
    "        wordsForCSV.append([democrat_mc[0], 0, democrat_mc[1]])\n",
    "\n",
    "  else:\n",
    "    if len(republican_list) > 1:\n",
    "      republican_mc = republican_list[(len(republican_list)-1)]\n",
    "      if (republican_mc, 1) in words:\n",
    "        words[(republican_mc[0], 1)]['lime_score'].extend(republican_mc[1])\n",
    "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
    "      else:\n",
    "        words[(republican_mc[0], 1)] = {}\n",
    "        words[(republican_mc[0], 1)]['lime_score'] = [republican_mc[1]]\n",
    "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
    "        wordsForCSV.append([republican_mc[0], 1, republican_mc[1]])\n",
    "\n",
    "      republican_mc = republican_list[(len(republican_list)-2)]\n",
    "      if (republican_mc, 1) in words:\n",
    "        words[(republican_mc[0], 1)]['lime_score'].extend(republican_mc[1])\n",
    "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
    "      else:\n",
    "        words[(republican_mc[0], 1)] = {}\n",
    "        words[(republican_mc[0], 1)]['lime_score'] = [republican_mc[1]]\n",
    "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
    "        wordsForCSV.append([republican_mc[0], 1, republican_mc[1]])\n",
    "\n",
    "    elif len(republican_list) == 1:\n",
    "      republican_mc = republican_list[0]\n",
    "      if (republican_mc, 1) in words:\n",
    "        words[(republican_mc[0], 1)]['lime_score'].extend(republican_mc[1])\n",
    "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
    "      else:\n",
    "        words[(republican_mc[0], 1)] = {}\n",
    "        words[(republican_mc[0], 1)]['lime_score'] = [republican_mc[1]]\n",
    "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
    "        wordsForCSV.append([republican_mc[0], 1, republican_mc[1]])\n",
    "\n",
    "\n",
    "  return words, wordsForCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gh8yt-7grxG6"
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "wordsForCSV = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "z8YBOZOVr0yY",
    "outputId": "dfe87cf5-2f9b-4dcb-a7a1-5b8b34f89078"
   },
   "outputs": [],
   "source": [
    "for tweet in tqdm(tweets, total = len(tweets)):\n",
    "  words, wordsForCSV = get_max_explained_words(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnoSxy59r4gW"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header=[\"word\", \"label\", \"limescore\"]\n",
    "\n",
    "with open('/content/drive/MyDrive/Datasets/Tweets/1_extracted_strong_words_by_bert_base_uncased.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(wordsForCSV)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
