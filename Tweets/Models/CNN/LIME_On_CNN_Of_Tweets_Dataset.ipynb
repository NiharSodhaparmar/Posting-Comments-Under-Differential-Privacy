{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHYKUrZnls_P",
        "outputId": "9a598711-acb4-4e21-dd1e-fa8d9d8ca902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m194.6/275.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283835 sha256=0ecf2ac4d8d06867560388dafd51577cbb4a96ea20f6bb3521d06054578c2840\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcitcR1Yh_Zn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "from operator import itemgetter\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_file):\n",
        "  # read csv file\n",
        "  df = pd.read_csv(data_file)\n",
        "\n",
        "  # replace nan(no value) comment with \"\"(empty string)\n",
        "  df.fillna(\"\", inplace=True)\n",
        "\n",
        "  tweets = df['Tweet'].tolist()\n",
        "  labels = df['Party'].tolist()\n",
        "\n",
        "  labels = [0 if label == \"Democrat\" else 1 for label in labels]\n",
        "\n",
        "  return tweets, labels"
      ],
      "metadata": {
        "id": "-pVTwFfdiTnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets, labels = load_data('/content/drive/MyDrive/Datasets/Tweets/ExtractedTweets.csv')"
      ],
      "metadata": {
        "id": "WoVuMD6FiYkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = np.array(tweets)\n",
        "labels = np.array(labels)\n",
        "\n",
        "len(tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOoNc9weiahs",
        "outputId": "9d32dfd7-1c2c-469f-859e-9e30a6322e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86460"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tweets = tweets[35370:86460]\n",
        "new_labels = labels[35370:86460]\n",
        "\n",
        "n = int(len(new_tweets) / 65)\n",
        "x = [tweets[i:i + n] for i in range(0, len(new_tweets), n)]\n",
        "y = [labels[i:i + n] for i in range(0, len(new_labels), n)]\n",
        "\n",
        "first_half_tweets = x[0]\n",
        "second_half_tweets = x[1]\n",
        "third_half_tweets = x[2]\n",
        "fourth_half_tweets = x[3]\n",
        "fifth_half_tweets = x[4]\n",
        "sixth_half_tweets = x[5]\n",
        "seventh_half_tweets = x[6]\n",
        "eighth_half_tweets = x[7]\n",
        "ninth_half_tweets = x[8]\n",
        "tenth_half_tweets = x[9]\n",
        "eleventh_half_tweets = x[10]\n",
        "twelveth_half_tweets = x[11]\n",
        "thirteenth_half_tweets = x[12]\n",
        "fourteenth_half_tweets = x[13]\n",
        "fifteen_half_tweets = x[14]\n",
        "sixteen_half_tweets = x[15]\n",
        "seventeen_half_tweets = x[16]\n",
        "eighteen_half_tweets = x[17]\n",
        "nineteen_half_tweets = x[18]\n",
        "twenty_half_tweets = x[19]\n",
        "twentyone_half_tweets = x[20]\n",
        "twentytwo_half_tweets = x[21]\n",
        "twentythree_half_tweets = x[22]\n",
        "twentyfour_half_tweets = x[23]\n",
        "twentyfive_half_tweets = x[24]\n",
        "twentysix_half_tweets = x[25]\n",
        "twentyseven_half_tweets = x[26]\n",
        "twentyeight_half_tweets = x[27]\n",
        "twentynine_half_tweets = x[28]\n",
        "thirty_half_tweets = x[29]\n",
        "thirtyone_half_tweets = x[30]\n",
        "thirtytwo_half_tweets = x[31]\n",
        "thirtythree_half_tweets = x[32]\n",
        "thirtyfour_half_tweets = x[33]\n",
        "thirtyfive_half_tweets = x[34]\n",
        "thirtysix_half_tweets = x[35]\n",
        "thirtyseven_half_tweets = x[36]\n",
        "thirtyeight_half_tweets = x[37]\n",
        "thirtynine_half_tweets = x[38]\n",
        "# fourty_half_tweets = x[39]\n",
        "# fourtyone_half_tweets = x[40]\n",
        "# fourtytwo_half_tweets = x[41]\n",
        "# fourtythree_half_tweets = x[42]\n",
        "# fourtyfour_half_tweets = x[43]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "first_half_labels = y[0]\n",
        "second_half_labels = y[1]\n",
        "third_half_labels = y[2]\n",
        "fourth_half_labels = y[3]\n",
        "fifth_half_labels = x[4]\n",
        "sixth_half_labels = x[5]\n",
        "seventh_half_labels = x[6]\n",
        "eighth_half_labels = x[7]\n",
        "ninth_half_labels = x[8]\n",
        "tenth_half_labels = x[9]\n",
        "eleventh_half_labels = x[10]\n",
        "twelveth_half_labels = x[11]\n",
        "thirteenth_half_labels = x[12]\n",
        "fourteenth_half_labels = x[13]\n",
        "fifteen_half_labels = x[14]\n",
        "sixteen_half_labels = x[15]\n",
        "seventeen_half_labels = x[16]\n",
        "eighteen_half_labels = x[17]\n",
        "nineteen_half_labels = x[18]\n",
        "twenty_half_labels = x[19]\n",
        "twentyone_half_labels = x[20]\n",
        "twentytwo_half_labels = x[21]\n",
        "twentythree_half_labels = x[22]\n",
        "twentyfour_half_labels = x[23]\n",
        "twentyfive_half_labels = x[24]\n",
        "twentysix_half_labels = x[25]\n",
        "twentyseven_half_labels = x[26]\n",
        "twentyeight_half_labels = x[27]\n",
        "twentynine_half_labels = x[28]\n",
        "thirty_half_labels = x[29]\n",
        "thirtyone_half_labels = x[30]\n",
        "thirtytwo_half_labels = x[31]\n",
        "thirtythree_half_labels = x[32]\n",
        "thirtyfour_half_labels = x[33]\n",
        "thirtyfive_half_labels = x[34]\n",
        "thirtysix_half_labels = x[35]\n",
        "thirtyseven_half_labels = x[36]\n",
        "thirtyeight_half_labels = x[37]\n",
        "thirtynine_half_labels = x[38]\n",
        "# fourty_half_labels = x[39]\n",
        "# fourtyone_half_labels = x[40]\n",
        "# fourtytwo_half_labels = x[41]\n",
        "# fourtythree_half_labels = x[42]\n",
        "# fourtyfour_half_labels = x[43]"
      ],
      "metadata": {
        "id": "zbmiLwADib_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad sequences\n",
        "max_words = 50000\n",
        "max_len = 128\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(tweets)\n",
        "sequences = tokenizer.texts_to_sequences(tweets)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "DKF5k4KPieX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GT7uXCLWk6wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and set memory growth to avoid issues\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "O8sGIX8vlIAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "embedding_dim = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "sEDU2CN9lNf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Emv32iUlRwV",
        "outputId": "96936ab0-8c30-43ce-a6a0-489ae1f87490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1730/1730 [==============================] - 26s 14ms/step - loss: 0.4624 - accuracy: 0.7655 - val_loss: 0.3672 - val_accuracy: 0.8233\n",
            "Epoch 2/3\n",
            "1730/1730 [==============================] - 15s 9ms/step - loss: 0.2655 - accuracy: 0.8848 - val_loss: 0.3828 - val_accuracy: 0.8306\n",
            "Epoch 3/3\n",
            "1730/1730 [==============================] - 14s 8ms/step - loss: 0.1470 - accuracy: 0.9417 - val_loss: 0.5038 - val_accuracy: 0.8212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x42aKRyklTuc",
        "outputId": "d2d89d53-e812-4350-ed5c-48d0d718217c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "541/541 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVHwNKaClWBw",
        "outputId": "82909c14-7736-4b05-ef1c-b6e2d6c940bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8162\n",
            "F1 Score: 0.8232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Datasets/Tweets/Saved Model/tweet_classification_model_cnn.h5')\n",
        "print(\"Model saved to tweet_classification_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLt5gERLlcQ9",
        "outputId": "0761de94-3bc0-492c-d4c3-fcb6ae6a675f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to tweet_classification_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prediction function\n",
        "def predict_party(tweet, tokenizer, model, max_len):\n",
        "    sequence = tokenizer.texts_to_sequences([tweet])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
        "    prediction = model.predict(padded_sequence)[0][0]\n",
        "    return 'Democrat' if prediction < 0.5 else 'Republican'"
      ],
      "metadata": {
        "id": "sOWQaP1Kn6gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(predict_party(tweets[0], tokenizer, model, max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9ITeIK8o8PC",
        "outputId": "844a5931-8fba-46e4-d96d-2d2196f925bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 280ms/step\n",
            "Democrat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to predict probabilities\n",
        "def predict_proba(texts):\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "    return np.array([[1 - pred[0], pred[0]] for pred in model.predict(padded_sequences)])"
      ],
      "metadata": {
        "id": "MTWuA4mspANY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LIME explainer\n",
        "explainer = LimeTextExplainer(class_names=['Democrat', 'Republican'])\n"
      ],
      "metadata": {
        "id": "EuV5rvZ-qDVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to explain predictions\n",
        "def explain_prediction(tweet):\n",
        "    explanation = explainer.explain_instance(tweet, predict_proba, num_features=10)\n",
        "    return explanation"
      ],
      "metadata": {
        "id": "NB42KsuzqE_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the explanation\n",
        "# exp.show_in_notebook(text=True)"
      ],
      "metadata": {
        "id": "VXTMw5I9qs2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_tuples_array_by_second_item(tuples):\n",
        "    # Sort the tuples by the second item using the itemgetter function\n",
        "    return sorted(tuples, key=itemgetter(1))"
      ],
      "metadata": {
        "id": "1o2nYPo_qzoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_explained_words(txt):\n",
        "\n",
        "  prediction = predict_party(model, txt, tokenizer, max_len)\n",
        "  # print(\" \")\n",
        "  # print(\"prediction\")\n",
        "  # print(prediction)\n",
        "\n",
        "  exp = explain_prediction(txt)\n",
        "\n",
        "  exp_list = []\n",
        "  for x in zip(exp.local_exp[1], exp.as_list()):\n",
        "    exp_list.append((x[1][0], x[1][1], x[0][0]))\n",
        "\n",
        "  # print(\"exp_list\")\n",
        "  # print(exp_list)\n",
        "\n",
        "  # features with negative score are for Male class\n",
        "  democrat_list = list(filter(lambda x: x[1] < 0, exp_list))\n",
        "  democrat_list = sort_tuples_array_by_second_item(democrat_list)\n",
        "\n",
        "  # print(\"democrat_list\")\n",
        "  # print(democrat_list)\n",
        "  # print(len(democrat_list))\n",
        "\n",
        "  # features with positive score are for female class\n",
        "  republican_list = list(filter(lambda x: x[1] > 0, exp_list))\n",
        "  republican_list = sort_tuples_array_by_second_item(republican_list)\n",
        "\n",
        "  # print(\"republican_list\")\n",
        "  # print(republican_list)\n",
        "  # print(len(republican_list))\n",
        "\n",
        "  # min is used while the democrat score is negative\n",
        "  democrat_mc = min(democrat_list, key=itemgetter(1)) if len(democrat_list) else None\n",
        "\n",
        "  # print(\"democrat_mc\")\n",
        "  # print(democrat_mc)\n",
        "\n",
        "  # max is used while the republican score is negative\n",
        "  republican_mc = max(republican_list, key=itemgetter(1)) if len(republican_list) else None\n",
        "\n",
        "  # print(\"republican_mc\")\n",
        "  # print(republican_mc)\n",
        "\n",
        "  # if comment predicted Male\n",
        "  if prediction == \"Democrat\":\n",
        "    if len(democrat_list) > 1:\n",
        "      democrat_mc = democrat_list[0]\n",
        "      if (democrat_mc, 0) in words:\n",
        "        words[(democrat_mc[0], 0)]['lime_score'].extend(democrat_mc[1])\n",
        "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
        "      else:\n",
        "        words[(democrat_mc[0], 0)] = {}\n",
        "        words[(democrat_mc[0], 0)]['lime_score'] = [democrat_mc[1]]\n",
        "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
        "        wordsForCSV.append([democrat_mc[0], 0, democrat_mc[1]])\n",
        "\n",
        "      democrat_mc = democrat_list[1]\n",
        "      if (democrat_mc, 0) in words:\n",
        "        words[(democrat_mc[0], 0)]['lime_score'].extend(democrat_mc[1])\n",
        "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
        "      else:\n",
        "        words[(democrat_mc[0], 0)] = {}\n",
        "        words[(democrat_mc[0], 0)]['lime_score'] = [democrat_mc[1]]\n",
        "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
        "        wordsForCSV.append([democrat_mc[0], 0, democrat_mc[1]])\n",
        "    elif len(democrat_list) == 1:\n",
        "      democrat_mc = democrat_list[0]\n",
        "      if (democrat_mc, 0) in words:\n",
        "        words[(democrat_mc[0], 0)]['lime_score'].extend(democrat_mc[1])\n",
        "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
        "      else:\n",
        "        words[(democrat_mc[0], 0)] = {}\n",
        "        words[(democrat_mc[0], 0)]['lime_score'] = [democrat_mc[1]]\n",
        "        words[(democrat_mc[0], 0)]['position'] = democrat_mc[2]\n",
        "        wordsForCSV.append([democrat_mc[0], 0, democrat_mc[1]])\n",
        "\n",
        "  else:\n",
        "    if len(republican_list) > 1:\n",
        "      republican_mc = republican_list[(len(republican_list)-1)]\n",
        "      if (republican_mc, 1) in words:\n",
        "        words[(republican_mc[0], 1)]['lime_score'].extend(republican_mc[1])\n",
        "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
        "      else:\n",
        "        words[(republican_mc[0], 1)] = {}\n",
        "        words[(republican_mc[0], 1)]['lime_score'] = [republican_mc[1]]\n",
        "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
        "        wordsForCSV.append([republican_mc[0], 1, republican_mc[1]])\n",
        "\n",
        "      republican_mc = republican_list[(len(republican_list)-2)]\n",
        "      if (republican_mc, 1) in words:\n",
        "        words[(republican_mc[0], 1)]['lime_score'].extend(republican_mc[1])\n",
        "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
        "      else:\n",
        "        words[(republican_mc[0], 1)] = {}\n",
        "        words[(republican_mc[0], 1)]['lime_score'] = [republican_mc[1]]\n",
        "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
        "        wordsForCSV.append([republican_mc[0], 1, republican_mc[1]])\n",
        "\n",
        "    elif len(republican_list) == 1:\n",
        "      republican_mc = republican_list[0]\n",
        "      if (republican_mc, 1) in words:\n",
        "        words[(republican_mc[0], 1)]['lime_score'].extend(republican_mc[1])\n",
        "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
        "      else:\n",
        "        words[(republican_mc[0], 1)] = {}\n",
        "        words[(republican_mc[0], 1)]['lime_score'] = [republican_mc[1]]\n",
        "        words[(republican_mc[0], 1)]['position'] = republican_mc[2]\n",
        "        wordsForCSV.append([republican_mc[0], 1, republican_mc[1]])\n",
        "\n",
        "\n",
        "  return words, wordsForCSV"
      ],
      "metadata": {
        "id": "kO0gMFlfrvHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = {}\n",
        "wordsForCSV = []"
      ],
      "metadata": {
        "id": "Gh8yt-7grxG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in tqdm(tweets, total = len(tweets)):\n",
        "  words, wordsForCSV = get_max_explained_words(tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "z8YBOZOVr0yY",
        "outputId": "dfe87cf5-2f9b-4dcb-a7a1-5b8b34f89078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/86460 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.str_' object has no attribute 'texts_to_sequences'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-528468d7f5e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordsForCSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_max_explained_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-13aef3b0ae7d>\u001b[0m in \u001b[0;36mget_max_explained_words\u001b[0;34m(txt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_max_explained_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_party\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m# print(\" \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# print(\"prediction\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-c46555ba3044>\u001b[0m in \u001b[0;36mpredict_party\u001b[0;34m(tweet, tokenizer, model, max_len)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define prediction function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_party\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpadded_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.str_' object has no attribute 'texts_to_sequences'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "header=[\"word\", \"label\", \"limescore\"]\n",
        "\n",
        "with open('/content/drive/MyDrive/Datasets/Tweets/1_extracted_strong_words_by_bert_base_uncased.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # write multiple rows\n",
        "    writer.writerows(wordsForCSV)\n"
      ],
      "metadata": {
        "id": "pnoSxy59r4gW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}